{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f489674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eaaf17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "effbcf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52b8005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5,0.5],\n",
    "                         [0.5,0.5,0.5])\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84739d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/fasal/projects/pytorch/FirstProject/Dataset/seg_train/seg_train'\n",
    "test_path = '/home/fasal/projects/pytorch/FirstProject/Dataset/seg_test/seg_test'\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform = transformer),\n",
    "    batch_size = 256,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform = transformer),\n",
    "    batch_size = 256,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "367210d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n"
     ]
    }
   ],
   "source": [
    "root = pathlib.Path(train_path)\n",
    "classes = sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d29f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn network\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes = 6,**kwargs):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #Output size after convolution filter\n",
    "        #((w-f+2P)/s)+1\n",
    "        \n",
    "        #Input shape(256,3,150,150)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape(256,12,150,150)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        #Shape(256,12,150,150)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #Shape(256,12,150,150), TO BRING THE NON-LINIEARITY\n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #Shape(256,12,75,75), TO REDUCE THE HIGHT AND WIDTH\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape(256,20,75,75)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Shape(256,20,75,75)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape(256,32,75,75)\n",
    "        self.bn2=nn.BatchNorm2d(num_features=32)\n",
    "        #Shape(256,32,75,75)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #Shape(256,32,75,75)\n",
    "        \n",
    "        self.fc=nn.Linear(in_features = 32*75*75,out_features = num_classes)\n",
    "        \n",
    "        \n",
    "        #Feed forward functions\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn2(output)\n",
    "        output=self.relu3(output)\n",
    "            \n",
    "        #Above output will be in matrix form, with shape(256,32,75,75)\n",
    "            \n",
    "        output=output.view(-1,32*75*75) # IN ORDER TO FEED IT INTO A FULLY CONNECTED LAYER, RESHAPE IT\n",
    "            \n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "446d22e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=6).to(device) #CALL THE COVNET CLASS AND THEN SEND TO TO THE DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b40d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f248f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "402ce10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating training and testing dataset count\n",
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f010efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14034 3000\n"
     ]
    }
   ],
   "source": [
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a82eafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0Train Loss:12Tain Accuracy:0.5218754453470144Test Accuracy:0.5723333333333334\n",
      "Epoch:1Train Loss:1Tain Accuracy:0.6882570899244691Test Accuracy:0.6846666666666666\n",
      "Epoch:2Train Loss:1Tain Accuracy:0.754952258800057Test Accuracy:0.7096666666666667\n",
      "Epoch:3Train Loss:0Tain Accuracy:0.8396038192959955Test Accuracy:0.7346666666666667\n",
      "Epoch:4Train Loss:0Tain Accuracy:0.867607239561066Test Accuracy:0.7163333333333334\n",
      "Epoch:5Train Loss:0Tain Accuracy:0.8899814735642012Test Accuracy:0.7443333333333333\n",
      "Epoch:6Train Loss:0Tain Accuracy:0.9289582442639305Test Accuracy:0.7246666666666667\n",
      "Epoch:7Train Loss:0Tain Accuracy:0.9330910645575032Test Accuracy:0.751\n",
      "Epoch:8Train Loss:0Tain Accuracy:0.9610232293002707Test Accuracy:0.7643333333333333\n",
      "Epoch:9Train Loss:0Tain Accuracy:0.9733504346586861Test Accuracy:0.7586666666666667\n"
     ]
    }
   ],
   "source": [
    "#Model trainig and saving best model\n",
    "\n",
    "best_accuracy=0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Evaluation and trainig on trainig dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    \n",
    "    for i,(images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(label.cuda())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss+=loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "    \n",
    "    #Evaluation on testing dataset\n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy=0.0\n",
    "    for i,(images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(label.cuda())\n",
    "            \n",
    "        outputs=model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "    test_accuracy=test_accuracy/test_count\n",
    "    \n",
    "    print('Epoch: '+str(epoch)+' Train_Loss: '+str(train_loss)+' Training_acc: '+str(train_accuracy)+' Test_acc: '+str(test_accuracy))\n",
    "    \n",
    "    #Save the best model\n",
    "    if test_accuracy>best_accuracy:\n",
    "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
    "        best_accuracy=test_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27343191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
